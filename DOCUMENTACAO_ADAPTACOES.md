# DocumentaÃ§Ã£o de AdaptaÃ§Ãµes: De CIFAR-10 para Dataset Customizado

## ğŸ“‹ VisÃ£o Geral das MudanÃ§as

Este documento detalha **todas as alteraÃ§Ãµes** feitas no notebook para transformÃ¡-lo de um exemplo acadÃªmico (CIFAR-10) em um pipeline **profissional e realista** de machine learning com dados customizados.

### PrincÃ­pio Principal
> **Em competiÃ§Ãµes Kaggle reais**: o arquivo `test.csv` **NÃƒO tem labels**. O modelo faz prediÃ§Ãµes em dados nunca vistos e vocÃª submete as prediÃ§Ãµes.

---

## ğŸ”„ MudanÃ§a 1: Imports (CÃ©lula 2)

### âŒ Problema com CÃ³digo Original
```python
from datasets import load_dataset  # Hugging Face datasets
```
- Acoplado ao formato HuggingFace
- Menos flexÃ­vel para dados customizados
- DifÃ­cil estender para novos tipos de dados

### âœ… SoluÃ§Ã£o Implementada
```python
import pandas as pd
import os
from torch.utils.data import Dataset, DataLoader, random_split
```

### ğŸ“š Por QuÃª?
1. **pandas**: Manipular CSVs Ã© simples e universal
2. **os**: Navegar sistema de arquivos (padrÃ£o em ML real)
3. **Dataset**: Classe base do PyTorch - padrÃ£o da indÃºstria
4. **random_split**: Dividir train/val mantendo ordem

### ğŸ¯ Quando Usar
- Dados em pasta + CSV (99% das aplicaÃ§Ãµes reais)
- Projetos independentes de plataformas
- Quando precisa customizar carregamento de dados

---

## ğŸ—‚ï¸ MudanÃ§a 2: Criar CustomImageDataset (CÃ©lula 3)

### âŒ Problema Original
```python
trainds, testds = load_dataset("cifar10", split=["train[:5000]","test[:1000]"])
```
- HuggingFace lida tudo internamente
- Opaco: nÃ£o sabemos como dados sÃ£o carregados
- DifÃ­cil adaptar para test set sem labels

### âœ… SoluÃ§Ã£o: Classe CustomImageDataset
```python
class CustomImageDataset(Dataset):
    def __init__(self, csv_file, img_dir, transform=None, has_labels=True):
        self.df = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.has_labels = has_labels
        # ...
    
    def __getitem__(self, idx):
        # Carregar imagem
        # Se tem_labels: retornar label
        # Se nÃ£o tem_labels: retornar None/skip (CENÃRIO KAGGLE)
```

### ğŸ“Š ComparaÃ§Ã£o de Estruturas

| Aspecto | Antigo (CIFAR-10) | Novo (Customizado) |
|---------|-------------------|-------------------|
| Fonte | Hugging Face | CSV + Pasta |
| Train/Val | Dividir HF dataset | random_split |
| Test labels | Tem labels | **SEM labels** âœ“ |
| Flexibilidade | Nenhuma | Completa |
| Debugging | DifÃ­cil | Simples |

### ğŸ¯ Vantagem Principal
```python
# VocÃª controla tudo:
# 1. Onde estÃ£o os dados (caminho)
# 2. Como carregar (transformaÃ§Ãµes)
# 3. O que retornar (pixels, labels, file_id)
# 4. Lidar com dados sem labels (REAL!)
```

---

## ğŸ”¢ MudanÃ§a 3: Classes DinÃ¢micas (CÃ©lula 4)

### âŒ CÃ³digo Original
```python
# CIFAR-10 tem exatamente 10 classes, hardcoded:
itos = dict((k,v) for k,v in enumerate(trainds.features['label'].names))
# Resultado: ['airplane', 'automobile', 'bird', ...]
```

### âœ… CÃ³digo Novo
```python
class_names = [f'class_{i}' for i in full_dataset.classes]
itos = dict(enumerate(class_names))
# Descobre automaticamente do CSV!
```

### âš™ï¸ Como Funciona
1. **DetecÃ§Ã£o automÃ¡tica**: `full_dataset.classes` = valores Ãºnicos no CSV
2. **GenÃ©rico**: Funciona para 2, 10, 100, ou 1000 classes
3. **RastreÃ¡vel**: Cada classe tem nome Ãºnico (class_0, class_1, etc)

### ğŸ“ˆ Exemplo PrÃ¡tico
```
train.csv contÃ©m:
file_id,class
19661,0
10805,0
...
11377,1
10546,1

full_dataset.classes = [0, 1]
itos = {0: 'class_0', 1: 'class_1'}
stoi = {'class_0': 0, 'class_1': 1}
```

---

## ğŸ“¸ MudanÃ§a 4: Aplicar TransformaÃ§Ãµes (CÃ©lula 8)

### âŒ Problema
```python
# HuggingFace tem mÃ©todo set_transform:
trainds.set_transform(transf)
```
- MÃ©todo especÃ­fico de HF Dataset
- NÃ£o funciona com PyTorch Dataset genÃ©rico

### âœ… SoluÃ§Ã£o: TransformDataset Wrapper
```python
class TransformDataset(Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform
    
    def __getitem__(self, idx):
        sample = self.dataset[idx]
        if self.transform:
            sample['pixels'] = self.transform(sample['img'])
        return sample

trainds = TransformDataset(trainds, transform=_transf)
```

### ğŸ¤” Por QuÃª?
1. **PadrÃ£o PyTorch**: TransformaÃ§Ãµes sÃ£o aplicadas em `__getitem__`
2. **Eficiente**: Carrega imagem + transforma sob demanda (lazy loading)
3. **ReutilizÃ¡vel**: Funciona com qualquer Dataset

---

## ğŸ¯ MudanÃ§a 5: DinÃ¢mica de Classes no Modelo (CÃ©lula 11)

### âŒ Hardcoded (Antigo)
```python
model = ViTForImageClassification.from_pretrained(
    model_name, 
    num_labels=10,  # ğŸ”´ CIFAR-10 especÃ­fico!
    ...
)
```

### âœ… DinÃ¢mico (Novo)
```python
num_labels = len(full_dataset.classes)  # AutomÃ¡tico!
model = ViTForImageClassification.from_pretrained(
    model_name, 
    num_labels=num_labels,  # ğŸŸ¢ Qualquer nÃºmero
    ...
)
```

### ğŸ”„ Impacto
- **Antes**: Mudar CIFAR-10 â†’ novo dataset = editar cÃ³digo
- **Depois**: Simplesmente mudar CSV, model se adapta!

---

## ğŸ“¦ MudanÃ§a 6: collate_fn com file_ids (CÃ©lula 13)

### âŒ CÃ³digo Original
```python
def collate_fn(examples):
    pixels = torch.stack([example["pixels"] for example in examples])
    labels = torch.tensor([example["label"] for example in examples])
    return {"pixel_values": pixels, "labels": labels}
    # âŒ Perde informaÃ§Ã£o de file_id!
```

### âœ… CÃ³digo Novo
```python
def collate_fn(examples):
    pixels = torch.stack([example["pixels"] for example in examples])
    labels = torch.tensor([example["label"] for example in examples])
    file_ids = [example["file_id"] for example in examples]  # âœ… NOVO
    return {
        "pixel_values": pixels, 
        "labels": labels,
        "file_id": file_ids  # Rastrear para submissÃ£o Kaggle
    }
```

### ğŸ¯ Por QuÃª?
```
Para submissÃ£o Kaggle, vocÃª precisa de:
  file_idâ‚ â†’ class_preditoâ‚
  file_idâ‚‚ â†’ class_preditoâ‚‚
  ...

Sem rastrear file_id, vocÃª perde a correspondÃªncia!
```

---

## ğŸ”® MudanÃ§a 7: Test Predictions SEM Labels (CÃ©lula 16)

### âŒ Problema (CIFAR-10)
```python
# CIFAR-10 test tinha labels
outputs = trainer.predict(testds)
print(outputs.metrics)  # Pode calcular accuracy
```

### âœ… Realidade (Kaggle)
```python
# Test set NÃƒO tem labels!
outputs = trainer.predict(testds)  # Sem labels = sem .metrics

# Mas temos:
predicted_classes = np.argmax(outputs.predictions, axis=1)
# â†’ Estas sÃ£o as prediÃ§Ãµes para submissÃ£o
```

### ğŸš¨ ConsequÃªncia
```
âŒ ERRADO: comparar prediÃ§Ãµes test com labels (nÃ£o existem!)
âœ… CERTO: submeter prediÃ§Ãµes ao Kaggle, eles verificam

Isso muda TUDO a forma de validar!
```

---

## ğŸ“ MudanÃ§a 8: Gerar Arquivo de SubmissÃ£o (CÃ©lula 17 - NOVO)

### âš ï¸ Este cÃ³digo nÃ£o existia antes!

```python
# CÃ©lula completamente nova para workflow Kaggle

test_file_ids = []
for i in range(len(testds.dataset)):
    sample = testds.dataset[i]
    test_file_ids.append(sample['file_id'])

submission_df = pd.DataFrame({
    'file_id': test_file_ids,
    'class': predicted_classes
})

submission_df.to_csv('submission.csv', index=False)
```

### ğŸ¯ Fluxo Real
```
1. Treinar em train.csv (com labels)
2. Fazer predictions em test.csv (sem labels)
3. Criar CSV: file_id, class_predito
4. Enviar para Kaggle
5. Kaggle compara com labels verdadeiros (que vocÃª nÃ£o tem)
6. Recebe score pÃºblico
```

---

## ğŸ“Š MudanÃ§a 9: AnÃ¡lise em Validation Set (CÃ©lula 18)

### âŒ Antigo
```python
# Analisava test set:
y_true = outputs.label_ids  # test set labels (CIFAR-10 tinha)
y_pred = outputs.predictions.argmax(1)
# Confusion matrix no test
```

### âœ… Novo
```python
# Analisa validation set (que sempre tem labels):
val_outputs = trainer.predict(valds)  # â† val nÃ£o test!
y_true = y_true  # labels do val
y_pred = np.argmax(val_outputs.predictions, axis=1)
# Confusion matrix no val
```

### ğŸ” DiferenÃ§a CrÃ­tica
| Dataset | Labels? | Uso |
|---------|---------|-----|
| **Train** | âœ… Sim | Treinar modelo |
| **Val** | âœ… Sim | Monitorar progresso, analyzePerformance |
| **Test** | âŒ NÃ£o | Fazer prediÃ§Ãµes para submissÃ£o |

---

## ğŸ“ Conceitos Aprofundados

### 1ï¸âƒ£ Transfer Learning e NormalizaÃ§Ã£o

```python
# Por que usar ImageNet mean/std?
mu = [0.485, 0.456, 0.406]  # ImageNet average pixel values
sigma = [0.229, 0.224, 0.225]  # ImageNet std dev

# Modelo foi TREINADO em ImageNet com estes valores
# Usar diferentes valores = distribuiÃ§Ã£o input diferente
# = Pesos prÃ©-treinados perdem efetividade

# Analogia: treinar alguÃ©m a ler metros, depois medir em feet
```

### 2ï¸âƒ£ Data Leakage

```python
# âŒ NUNCA fazer isto:
train_val_combined = load_all_data()
splits = train_test_split(train_val_combined)

# âœ… CORRETO:
train = load_train_data()
val = load_val_data()  # Ou dividir train
test = load_test_data()

# RazÃ£o: dados de teste nunca devem influenciar modelo
```

### 3ï¸âƒ£ Stratified Splits

```python
# random_split mantÃ©m proporÃ§Ãµes?
# NÃƒO! Para dados desbalanceados, use:
from sklearn.model_selection import train_test_split

indices = np.arange(len(full_dataset))
labels = full_dataset.df['class'].values

train_idx, val_idx = train_test_split(
    indices, 
    test_size=0.1, 
    stratify=labels  # â† Garante mesma distribuiÃ§Ã£o
)
```

---

## ğŸ› ï¸ Como Estender Este CÃ³digo

### CenÃ¡rio 1: Adicionar mais dados
```python
# Antes:
# 1. Tirar data antigo
# 2. Reescrever cÃ³digo

# Depois:
# 1. Colocar novas imagens em /data/train/
# 2. Adicionar linhas em train.csv
# 3. PRONTO! Rodar notebook novamente
```

### CenÃ¡rio 2: Mudar para multi-label
```python
# train.csv atual:
# file_id,class
# 19661,0

# Multi-label:
# file_id,class
# 19661,"0,1,3"

# Adaptar CustomImageDataset.__getitem__:
labels = [int(x) for x in label_str.split(',')]
return {
    'pixels': pixels,
    'labels': labels,  # Agora lista de labels
    'file_id': file_id
}
```

### CenÃ¡rio 3: Usar data augmentation
```python
from torchvision.transforms import RandomHorizontalFlip, RandomRotation

_transf = Compose([
    RandomHorizontalFlip(p=0.5),      # Novo!
    RandomRotation(degrees=15),        # Novo!
    Resize(size['height']),
    ToTensor(),
    norm
])
# AutomÃ¡ticamente aplicado durante treinamento
```

---

## ğŸ¯ ComparaÃ§Ã£o Lado-a-Lado

### Fluxo CIFAR-10 (Original)
```
1. load_dataset("cifar10")  â† AutomÃ¡tico, predefinido
2. train_test_split()
3. TransformaÃ§Ãµes via set_transform
4. Treinar em train/val
5. Testar em test (COM labels verdadeiros)
6. Confusion matrix = âœ“ Valida tudo
```

### Fluxo Customizado (Novo) â­
```
1. Ler train.csv (com labels) â† VocÃª controla
2. Ler test.csv (SEM labels) â† Realista!
3. CustomImageDataset + TransformDataset
4. Treinar em train/val
5. Prever em test (SEM labels)
6. Gerar submission.csv para Kaggle
7. Kaggle valida (vocÃª nunca vÃª test labels)
```

---

## ğŸ“š Para Aprofundar

### TÃ³picos Relacionados
1. **Data Augmentation** - Aumentar dataset sinteticamente
2. **Class Imbalance** - Lidar com classes desbalanceadas
3. **Hyperparameter Tuning** - Otimizar learning_rate, batch_size, etc
4. **Cross-Validation** - ValidaÃ§Ã£o mais robusta
5. **Ensemble Methods** - Combinar mÃºltiplos modelos
6. **Interpretability** - Entender decisÃµes do modelo (Grad-CAM, etc)

### ExercÃ­cios Propostos
1. **FÃ¡cil**: Adicionar 100 novas imagens ao dataset
2. **MÃ©dio**: Implementar class weighting para classes desbalanceadas
3. **DifÃ­cil**: Implementar k-fold cross-validation
4. **AvanÃ§ado**: Usar model ensemble (5 modelos) para submissÃ£o final

---

## ğŸ”— ReferÃªncias

- [PyTorch Dataset Documentation](https://pytorch.org/docs/stable/data.html)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)
- [Vision Transformer Paper](https://arxiv.org/abs/2010.11929)
- [Kaggle Competitions Guide](https://www.kaggle.com/docs/competitions)

---

## âœ… Checklist: Estrutura Profissional

- [x] CÃ³digo sem labels no test set (realista)
- [x] CustomImageDataset genÃ©rico e reutilizÃ¡vel
- [x] Rastreamento de file_ids para submissÃ£o
- [x] Validation set para anÃ¡lise (nÃ£o test!)
- [x] Confusion matrix interpretÃ¡vel
- [x] Arquivo de submissÃ£o em formato Kaggle
- [x] DocumentaÃ§Ã£o inline das mudanÃ§as
- [x] CÃ³digo antigo comentado para comparaÃ§Ã£o
- [x] ExtensÃ­vel para novos dados

---

**VersÃ£o**: 1.0  
**Data**: 14/01/2026  
**Status**: âœ… Pronto para produÃ§Ã£o
